{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist4beginners.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqKCSUGsLOmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Code writen by Dweep Joshipura\n",
        "Blog - lightspeedac.blogspot.com\n",
        "Please read the comments carefully\n",
        "'''\n",
        "# Go to Edit->Notebook Setting->Hardware Accelerator->Select GPU and Save\n",
        "# Doing the above will speed up your training tremendously, and save time.\n",
        "# Importing Keras programming framework\n",
        "import keras \n",
        "# Ensuring that TensorFlow v1 is used as backend\n",
        "%tensorflow_version 1.x \n",
        "# Importing kinds of layers\n",
        "from keras.layers import Dense,Dropout\n",
        "# Importing a basic model type\n",
        "from keras.models import Sequential\n",
        "# Importing the DIGIT CLASSIFIER dataset \n",
        "from keras.datasets import mnist \n",
        "# Importing a function used later\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NMvajRDV38l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mnist_preprocess(X):\n",
        "  '''\n",
        "  This function takes the Inputs and Reshapes them into 2 dim matrices\n",
        "  It also normalizes the Input\n",
        "  '''\n",
        "  X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
        "  X = X.astype('float32')\n",
        "  X /= 255\n",
        "  return X\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aBcQoMDM5Yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "94701b8c-660e-4284-adbb-ebbf93128dc6"
      },
      "source": [
        "\n",
        "# the number can be of 10 types (0,1,2,3,4,5,6,7,8,9)\n",
        "num_classes = 10\n",
        "'''\n",
        "Here-\n",
        "X = input for Neural Network\n",
        "Y = ground truth labels for input X for NN to train on\n",
        "X_test = testing inputs we will use after training\n",
        "Y_test = ground truth labels for input X_test to evaluate NN.\n",
        "The dataset MNIST has 60000 training examples and 10000 test examples.\n",
        "'''\n",
        "(X,Y),(X_test,Y_test) = mnist.load_data()\n",
        "# Preprocesses the data\n",
        "X = mnist_preprocess(X)\n",
        "X_test = mnist_preprocess(X_test)\n",
        "# Preprocesses Y\n",
        "Y = to_categorical(Y,num_classes)\n",
        "Y_test = to_categorical(Y_test,num_classes)\n",
        "\n",
        "# As the name suggests, the Sequential model uses sequence of layers to automatically create NN\n",
        "model = Sequential(name=\"my-first-NN\")\n",
        "'''\n",
        "The first type of layer is the one we've talked about in blog.\n",
        "We are having one layer consisting of 64 units computing the same function, although with different parameters.\n",
        "This will enable more complexity.\n",
        "The activation is ReLU, which is just a graph like _/ which eliminates negative numbers by giving them value of zero.\n",
        "To automatically build a model, the first layer needs to be given the shape of the input.\n",
        "'''\n",
        "model.add(Dense(units=64,activation='relu',input_shape=(X.shape[1],)))\n",
        "'''\n",
        "Another type of layer is Dropout, which, to increase robustness randomly eliminates some percentage of units.\n",
        "This will enable better accuracy and training speed\n",
        "The rate is a parameter which we'll have to set. rate = 0.5 will mean that half of the units shall be randomly eliminated\n",
        "'''\n",
        "model.add(Dropout(rate=0.2))\n",
        "# We will add few more group of layers like this one. You may play around with num of units and dropout rate\n",
        "model.add(Dense(units=512,activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(units=512,activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "'''\n",
        "The problem we are currently tackling, requires multiple 0 or 1 outputs.\n",
        "Such 'multi-class classification problems' use softmax function\n",
        "NOTE: As we have ten classes the units = num_classes shouldn't be changed\n",
        "'''\n",
        "model.add(Dense(units = num_classes, activation = 'softmax'))\n",
        "#In the summary, you can see that there are lot of params!!\n",
        "model.summary()\n",
        "'''This will specify the loss as categorical loss and optimizer as Adam\n",
        "Details about Adam are beyond the scope of this blog'''\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "# This will train our models' all examples 20 times\n",
        "model.fit(x = X,y = Y,epochs = 20,verbose = 0)\n",
        "score = model.evaluate(X_test,Y_test,verbose = 0)\n",
        "print('Test accuracy = '+ str(score[1]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my-first-NN\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_80 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 379,658\n",
            "Trainable params: 379,658\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "10000/10000 [==============================] - 1s 122us/step\n",
            "Test accuracy = 0.9763\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
